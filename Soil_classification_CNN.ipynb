{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcbac1e4-022f-4947-8603-ea97f2e05407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/valid split...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:\\\\soil_clasification\\\\Soil types\\\\unhealthy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(train_dir) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(valid_dir):\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating train/valid split...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m     \u001b[43mcreate_train_valid_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Filter corrupted images\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_corrupted_images\u001b[39m(directory):\n",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m, in \u001b[0;36mcreate_train_valid_split\u001b[1;34m(dataset_dir, split_ratio)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munhealthy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHealthy\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     18\u001b[0m     category_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_dir, category)\n\u001b[1;32m---> 19\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     split_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(images) \u001b[38;5;241m*\u001b[39m split_ratio)\n\u001b[0;32m     21\u001b[0m     train_images \u001b[38;5;241m=\u001b[39m images[:split_idx]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'E:\\\\soil_clasification\\\\Soil types\\\\unhealthy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "\n",
    "# Define paths\n",
    "dataset_dir = r'E:\\soil_clasification\\Soil types'\n",
    "train_dir = os.path.join(dataset_dir, r\"E:\\soil_clasification\\Soil types/train\")\n",
    "valid_dir = os.path.join(dataset_dir, r\"E:\\soil_clasification\\Soil types/valid\")\n",
    "\n",
    "# Ensure dataset has \"train\" and \"valid\" directories\n",
    "# If not, split them manually:\n",
    "def create_train_valid_split(dataset_dir, split_ratio=0.8):\n",
    "    for category in [\"unhealthy\", \"Healthy\"]:\n",
    "        category_path = os.path.join(dataset_dir, category)\n",
    "        images = os.listdir(category_path)\n",
    "        split_idx = int(len(images) * split_ratio)\n",
    "        train_images = images[:split_idx]\n",
    "        valid_images = images[split_idx:]\n",
    "\n",
    "        # Create subdirectories for train/valid split\n",
    "        os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
    "        os.makedirs(os.path.join(valid_dir, category), exist_ok=True)\n",
    "\n",
    "        # Move files to respective folders\n",
    "        for img in train_images:\n",
    "            os.rename(\n",
    "                os.path.join(category_path, img),\n",
    "                os.path.join(train_dir, category, img)\n",
    "            )\n",
    "        for img in valid_images:\n",
    "            os.rename(\n",
    "                os.path.join(category_path, img),\n",
    "                os.path.join(valid_dir, category, img)\n",
    "            )\n",
    "\n",
    "# Create train/valid split (run this only once)\n",
    "if not os.path.exists(train_dir) or not os.path.exists(valid_dir):\n",
    "    print(\"Creating train/valid split...\")\n",
    "    create_train_valid_split(dataset_dir)\n",
    "\n",
    "# Filter corrupted images\n",
    "def filter_corrupted_images(directory):\n",
    "    for folder_name in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder_name)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                img = load_img(file_path)\n",
    "                _ = img_to_array(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Removing corrupted image: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "\n",
    "print(\"Filtering corrupted images...\")\n",
    "filter_corrupted_images(train_dir)\n",
    "filter_corrupted_images(valid_dir)\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Load data\n",
    "batch_size = 32\n",
    "img_size = (150, 150)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    ")\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    ")\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_data,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"soil_texture_cnn_model.h5\")\n",
    "\n",
    "print(\"Model training completed and saved as 'soil_texture_cnn_model.h5'.\")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(valid_data)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db299f1-d4e1-4b0b-a1db-1afe420034dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
